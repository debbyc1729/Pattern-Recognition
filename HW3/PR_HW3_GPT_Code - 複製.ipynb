{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZQD8NqPhKyBP"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score # Please note that this is the only sklearn function that can be utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YV1MHt_VTg9f"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a1vkTOD6K5Nj"
   },
   "outputs": [],
   "source": [
    "# Load the train/val/test dataset\n",
    "\n",
    "df_train = pd.DataFrame(pd.read_csv(\"./PR_HW3_Train.csv\"))\n",
    "df_val   = pd.DataFrame(pd.read_csv(\"./PR_HW3_Val.csv\"))\n",
    "df_test  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
    "#df_test  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test_Keep.csv\"))\n",
    "\n",
    "X_train = df_train[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_train = df_train[\"Target\"].to_numpy()\n",
    "\n",
    "X_val = df_val[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_val = df_val[\"Target\"].to_numpy()\n",
    "\n",
    "X_test = df_test[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_test = df_test[\"Target\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MJcktFIuK78Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 7)\n",
      "(800,)\n",
      "(800, 7)\n",
      "(800,)\n",
      "(800, 7)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa3hnJ9sTkvh"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5e_nviB8LAK8"
   },
   "outputs": [],
   "source": [
    "def gini(sequence):\n",
    "    classes, counts = np.unique(sequence, return_counts=True)\n",
    "    impurity = 1.0\n",
    "    for count in counts:\n",
    "        prob = count / len(sequence)\n",
    "        impurity -= prob ** 2\n",
    "    return impurity\n",
    "\n",
    "def entropy(sequence):\n",
    "    classes, counts = np.unique(sequence, return_counts=True)\n",
    "    impurity = 0.0\n",
    "    for count in counts:\n",
    "        prob = count / len(sequence)\n",
    "        impurity -= prob * np.log2(prob)\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_HJA_108LF_G"
   },
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    \"\"\"\n",
    "        You can add/change any variables/methods to meet your need.\n",
    "    \"\"\"\n",
    "    def __init__(self):       \n",
    "        self.feature = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.output = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O_vgKCIwLdS0"
   },
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, criterion='gini', max_depth=None, max_features=None):\n",
    "        \n",
    "        \"\"\"\n",
    "            You can add/change any variables/methods to meet your need.\n",
    "        \"\"\"\n",
    "\n",
    "        if criterion == 'gini':\n",
    "            self.criterion = gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.criterion = entropy\n",
    "        \n",
    "        if max_depth is None:\n",
    "            self.max_depth = 1e9\n",
    "        else:\n",
    "            self.max_depth = max_depth\n",
    "\n",
    "        self.importance = {}\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        def build_tree(X, y, depth, sample_weight):\n",
    "            tree = Tree()\n",
    "            if depth >= self.max_depth:\n",
    "                tree.output = np.bincount(y, weights=sample_weight).argmax()\n",
    "                return tree\n",
    "            \n",
    "            if len(np.unique(y)) == 1:\n",
    "                tree.output = y[0]\n",
    "                return tree\n",
    "            \n",
    "            best_feature, best_threshold = self.find_best_split(X, y, sample_weight)\n",
    "\n",
    "            if best_feature is None or best_threshold is None:\n",
    "                tree.output = np.bincount(y, weights=sample_weight).argmax()\n",
    "                return tree\n",
    "\n",
    "            tree.feature = best_feature\n",
    "            tree.threshold = best_threshold\n",
    "\n",
    "            left_mask = []\n",
    "            right_mask = []\n",
    "            for i in range(len(X)):\n",
    "                if X[i, best_feature] <= best_threshold:\n",
    "                    left_mask.append(True)\n",
    "                    right_mask.append(False)\n",
    "                else:\n",
    "                    left_mask.append(False)\n",
    "                    right_mask.append(True)\n",
    "\n",
    "            tree.left = build_tree(X[left_mask], y[left_mask], depth + 1, sample_weight[left_mask])\n",
    "            tree.right = build_tree(X[right_mask], y[right_mask], depth + 1, sample_weight[right_mask])\n",
    "\n",
    "            return tree\n",
    "        \n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(len(X)) / len(X)\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = build_tree(X, y, 0, sample_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.empty(X.shape[0], dtype=int)\n",
    "        for i, x in enumerate(X):\n",
    "            tree = self.tree\n",
    "            while tree.threshold is None:\n",
    "                if x[tree.feature] <= tree.threshold:\n",
    "                    tree = tree.left\n",
    "                else:\n",
    "                    tree = tree.right\n",
    "            predictions[i] = tree.output\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def find_best_split(self, X, y, sample_weight):\n",
    "        num_features = X.shape[1]\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        if self.max_features:\n",
    "            feature_indices = np.random.choice(num_features, self.max_features, replace=False)\n",
    "        else:\n",
    "            feature_indices = range(num_features)\n",
    "\n",
    "        for feature in feature_indices:\n",
    "            column = X[:, feature]\n",
    "            thresholds = np.unique(column)\n",
    "            for threshold in thresholds:\n",
    "                y_left = y[column <= threshold]\n",
    "                y_right = y[column > threshold]\n",
    "                sw_left = sample_weight[column <= threshold]\n",
    "                sw_right = sample_weight[column > threshold]\n",
    "\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                gain = self.criterion(y, sample_weight) - len(y_left) / len(y) * self.criterion(y_left, sw_left) - len(y_right) / len(y) * self.criterion(y_right, sw_right)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "    \n",
    "    def countImportance(self):\n",
    "        if not hasattr(self, 'tree'):\n",
    "            raise ValueError(\"Tree has not been trained yet.\")\n",
    "\n",
    "        importance = np.zeros(self.n_features)\n",
    "        for tree in self.forest:\n",
    "            imp = np.zeros(self.n_features)\n",
    "            root = [tree]\n",
    "            while root:\n",
    "                tree = root.pop()\n",
    "                if hasattr(tree, 'threshold'):\n",
    "                    imp[tree.feature] += tree.n_samples\n",
    "                    root.append(tree.left)\n",
    "                    root.append(tree.right)\n",
    "            imp /= np.sum(imp)\n",
    "            importance += imp\n",
    "        self.importance = importance\n",
    "        return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BE8wu0MGN_H-"
   },
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    \"\"\"\n",
    "        You can add/change any variables/methods to meet your need.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.boostrap = boostrap\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # majority vote\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPUsaCh2T9Fs"
   },
   "source": [
    "# Questions for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zSB-Uqp4OaaX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+' '+' '+' '+' '+' '-']: entropy = 0.6500224216483541\n",
      "['+' '+' '+' '-' '-' '-']: entropy = 1.0\n",
      "['+' '-' '-' '-' '-' '-']: entropy = 0.6500224216483541\n",
      "\n",
      "['+' '+' '+' '+' '+' '-']: gini index = 0.2777777777777777\n",
      "['+' '+' '+' '-' '-' '-']: gini index = 0.5\n",
      "['+' '-' '-' '-' '-' '-']: gini index = 0.2777777777777777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For Q1\n",
    "ex1 = np.array([\"+\", \"+\", \"+\", \"+\", \"+\", \"-\"])\n",
    "ex2 = np.array([\"+\", \"+\", \"+\", \"-\", \"-\", \"-\"])\n",
    "ex3 = np.array([\"+\" ,\"-\", \"-\", \"-\", \"-\", \"-\"])\n",
    "\n",
    "print(f\"{ex1}: entropy = {entropy(ex1)}\\n{ex2}: entropy = {entropy(ex2)}\\n{ex3}: entropy = {entropy(ex3)}\\n\")\n",
    "print(f\"{ex1}: gini index = {gini(ex1)}\\n{ex2}: gini index = {gini(ex2)}\\n{ex3}: gini index = {gini(ex3)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G_t9N9fnOdon"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a9e64c6cee05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdt_depth3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdt_depth3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_depth3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'sample_weight'"
     ]
    }
   ],
   "source": [
    "# For Q2-1, validation accuracy should be higher than or equal to 0.73\n",
    "\n",
    "np.random.seed(0) # You may adjust the seed number in all the cells\n",
    "\n",
    "dt_depth3 = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
    "dt_depth3.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "acc = accuracy_score(y_val, dt_depth3.predict(X_val))\n",
    "\n",
    "print(\"Q2-1 max_depth=3: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0HcgzMdjHRP"
   },
   "outputs": [],
   "source": [
    "\"\"\" Do Not Modify Below \"\"\"\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as SK_DecisionTreeClassifier\n",
    "\n",
    "sk_dt = SK_DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
    "sk_dt.fit(X_train, y_train)\n",
    "sk_acc = accuracy_score(y_val, sk_dt.predict(X_val))\n",
    "\n",
    "assert round(acc, 3) == round(sk_acc, 3), \"Because the Decision Tree without any trick has a fixed answer, your accuracy should be the same as sklearn, otherwise your implementation might have some problems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjCPMr-eQ7jn"
   },
   "outputs": [],
   "source": [
    "# For Q2-2, validation accuracy should be higher than or equal to 0.85\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dt_depth10 = DecisionTree(criterion='gini', max_features=None, max_depth=10)\n",
    "dt_depth10.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "print(\"Q2-2 max_depth=10: \", accuracy_score(y_val,  dt_depth10.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTbxGPrbO2jT"
   },
   "outputs": [],
   "source": [
    "# For Q3-1, validation accuracy should be higher than or equal to 0.73\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dt_gini = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
    "dt_gini.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "print(\"Q3-1 criterion='gini': \", accuracy_score(y_val, dt_gini.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XG7eAKUQ-YU"
   },
   "outputs": [],
   "source": [
    "# For Q3-2, validation accuracy should be higher than or equal to 0.77\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dt_entropy = DecisionTree(criterion='entropy', max_features=None, max_depth=3)\n",
    "dt_entropy.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "print(\"Q3-2 criterion='entropy': \", accuracy_score(y_val, dt_entropy.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joE89xabPsXg"
   },
   "outputs": [],
   "source": [
    "# For Q4\n",
    "\n",
    "# Use simply counting to get the feature importance: dt_depth10.importance\n",
    "\n",
    "labelList=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg97qz_xUGfP"
   },
   "source": [
    "# Questions for Random Rorest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlrdIW1ERJ8F"
   },
   "outputs": [],
   "source": [
    "# For Q6-1, validation accuracy should be higher than or equal to 0.88\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "rf_estimators10 = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_estimators10.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q6-1 n_estimators=10: \", accuracy_score(y_val, rf_estimators10.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qcLuIkbRUfM"
   },
   "outputs": [],
   "source": [
    "# For Q6-2, validation accuracy should be higher than or equal to 0.89\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "rf_estimators50 = RandomForest(n_estimators=50, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_estimators50.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q6-1 n_estimators=50: \", accuracy_score(y_val, rf_estimators50.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-DbniYhRYmM"
   },
   "outputs": [],
   "source": [
    "# For Q7-1, validation accuracy should be higher than or equal to 0.88\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "rf_maxfeature_sqrt = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_maxfeature_sqrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q7-1 max_features='sqrt': \", accuracy_score(y_val,  rf_maxfeature_sqrt.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PF9yufSaRffn"
   },
   "outputs": [],
   "source": [
    "# For Q7-2, validation accuracy should be higher than or equal to 0.86\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "rf_maxfeature_none = RandomForest(n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_maxfeature_none.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q7-1 max_features='All': \", accuracy_score(y_val, rf_maxfeature_none.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjopdAZqUKbF"
   },
   "source": [
    "# Train your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Va4L29gfUPO8"
   },
   "outputs": [],
   "source": [
    "# Build and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cmxQjK3Rja9"
   },
   "outputs": [],
   "source": [
    "test_pred = your_model.predict(X_test)\n",
    "\n",
    "print(\"test_pred shape: \", test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCaZ4yFuR34B"
   },
   "outputs": [],
   "source": [
    "# output csv\n",
    "df_test = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
    "df_test[\"Target\"] = test_pred\n",
    "df_test.to_csv(\"sample_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YV1MHt_VTg9f"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
